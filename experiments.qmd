---
title: "Fair clustering experiments"
execute:
  echo: false
  warning: false
  message: false
---

Crucial observation: there are some clusters where their cluster center is not contained in the cluster
itself. 
As a particular case, there are some clusters that are emtpy,
making the budget of clusters underutilized.

```{r definitions}
library(tidyverse)
library(ggrepel)
library(kableExtra)
theme_set(theme_bw() + theme(legend.position="top"))

theme_paper <- function() {
  theme_bw() +
    theme(
      legend.position = "top",
      strip.background = element_blank(),
      strip.text = element_text(hjust=0),
      plot.margin = margin(0,0,0,0)
    )
}

scale_algorithm <- function() {
  list(
    scale_color_manual(values = c(
      "coreset" = "#5778a4",
      "coreset-MR" = "#5778a4",
      "coreset-stream" = "#5778a4",
      "KFC" = "#e49444",
      "unfair" = "#85b6b2",
      "Bera-et-al" = "#d1615d",
      "Bera-et-al-MR" = "#d1615d",
      "Bera-et-al-stream" = "#d1615d",
      "dummy" = "black"
    ), aesthetics=c("color", "fill")),
    scale_shape_manual(values = c(
      "coreset" = 19,
      "coreset-MR" = 19,
      "coreset-stream" = 19,
      "KFC" = 17,
      "unfair" = 18,
      "Bera-et-al" = 15,
      "Bera-et-al-MR" = 15,
      "Bera-et-al-stream" = 15,
      "dummy" = 8
    ))
  )
}

imgdir <- "imgs"

imgpath <- function(key) {
  str_c(imgdir, key, "clustering.png", sep="/")
}

dataset_stats <- function() {
  con <- DBI::dbConnect(RSQLite::SQLite(), "results.db")
  stats <- tbl(con, "dataset_stats") |> collect()
  DBI::dbDisconnect(con)
  stats
}

load_data <- function(delta_val = 0.01, mr = FALSE, streaming = FALSE, do_summarise = TRUE) {
  con <- DBI::dbConnect(RSQLite::SQLite(), "results.db")

  if (mr) {
    algofilter <- "algorithm like '%mr%'"
    additional_col <- "json_extract(params, '$.parallelism') as parallelism, 0 as streaming_memory_bytes,"
  } else if (streaming) {
    algofilter <- "algorithm like '%stream%'"
    additional_col <- "1 as parallelism, json_extract(additional_metrics, '$.streaming_memory_bytes') as streaming_memory_bytes,"
  } else {
    algofilter <- "algorithm not like '%mr%' and algorithm not like '%stream%'"
    additional_col <- "1 as parallelism, 0 as streaming_memory_bytes,"
  }

  q <- str_glue(
      "select *, 
       json_extract(params, '$.tau') / k as tau,
       json_extract(params, '$.epsilon') as epsilon,
       {additional_col}
       cast(additional_metrics -> '$.coreset_radius' as real) as coreset_radius,
       cast(additional_metrics -> '$.time_coreset_s' as real) as coreset_time_s,
       cast(additional_metrics -> '$.time_assignment_s' as real) as time_assignment_s
       from results
       where dataset not like '%std'
       and dataset not like 'census1990'
       and {algofilter}")

  smallest_radius <- tbl(con, sql("select dataset, k, min(radius) as best_unfair_radius from results group by dataset, k")) |> collect()

  results <- tbl(con, sql(q)) |> 
    inner_join(tbl(con, "dataset_stats")) |>
    collect() |>
    inner_join(smallest_radius) |>
    mutate(
      scaled_radius = radius / best_unfair_radius,
      dataset = case_when(
        dataset == "reuter_50_50" ~ "reuter",
        dataset == "census1990_age" ~ "census1990",
        T ~ dataset
      ),
      algorithm = case_when(
        algorithm == "coreset-fair-k-center" ~ "coreset",
        algorithm == "kfc-k-center" ~ "KFC",
        algorithm == "unfair-k-center" ~ "unfair",
        algorithm == "bera-et-al-k-center" ~ "Bera-et-al",
        algorithm == "bera-mr-fair-k-center" ~ "Bera-et-al-MR",
        algorithm == "bera-streaming-fair-k-center" ~ "Bera-et-al-stream",
        algorithm == "mr-coreset-fair-k-center" ~ "coreset-MR",
        algorithm == "streaming-coreset-fair-k-center" ~ "coreset-stream",
        T ~ algorithm
      ),
      algorithm = factor(algorithm, ordered=TRUE, levels=c(
        "unfair", 
        "Bera-et-al", 
        "Bera-et-al-MR", 
        "Bera-et-al-stream", 
        "KFC", 
        "coreset",
        "coreset-MR", 
        "coreset-stream", 
        "dummy"
      )),
      timeout_s = if_else(time_s > 30*60, 30*60, timeout_s),
      timed_out = !is.na(timeout_s),
      time_s = if_else(timed_out, timeout_s, time_s),
      scaled_time_spp = time_s / n,
      scaled_coreset_time_spp = coreset_time_s / n,
      img_path = imgpath(hdf5_key),
      coreset_size_frac = tau * k / n,
      dataset = fct_reorder(dataset, desc(n))
    )

  if (do_summarise) {
    results <- results |>
      group_by(dataset, algorithm, k, delta, tau, epsilon, parallelism, timed_out, coreset_size_frac, n, dimensions) |>
      summarise(
        across(c(radius, scaled_radius, coreset_radius, 
                  time_s, coreset_time_s, time_assignment_s, streaming_memory_bytes
              ), mean),
        additive_violation = max(additive_violation)
      ) |>
      mutate(streaming_memory_bytes = as.double(streaming_memory_bytes)) |>
      ungroup()
  }

  if (!is.na(delta_val)) {
    message(paste("filtering by delta=", delta_val))
    results <- filter(results, delta == delta_val)
  }

  DBI::dbDisconnect(con)
  results
}

results <- load_data()
```

```{r}
dataojs <- results |>
  select(dataset, k, algorithm, tau, radius, time_s, scaled_radius, additive_violation) |>
  group_by(dataset, k, algorithm, tau) |>
  summarise(
    across(c(radius, time_s, scaled_radius), mean),
    additive_violation = max(additive_violation)
  )
ojs_define(data = dataojs)
```


```{r tab-dimensions}
dataset_stats() |>
  distinct(dataset, n, dimensions) |>
  arrange(desc(n)) |>
  kbl() |>
  kable_styling()
```

The following grid of plots provides and overview of the radius/time tradeoff for all algorithms.

```{r}
#| column: screen
#| out-width: "100%"
#| fig-width: 15
#| fig-height: 15

results |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point(data=~ filter(., timed_out), shape=21, color="black", fill="white", size=4) +
  geom_point() +
  facet_grid(vars(dataset), vars(k))
```

This plot instead shows how the radius changes for changing values of `k`.
Notably, the radius flattens earlier when the fairness is considered.
One thing to remember is that, as of now, we are aiming to preserve the _exact_ ratios:
i.e. $\alpha = \beta$, there is no slack in the balancing of each cluster.

```{r}
load_data() |>
  mutate(tau = if_else(is.na(tau), 0, tau)) |>
  ggplot(aes(k, radius, color=algorithm)) +
  geom_line(data=~filter(., algorithm != "coreset")) +
  geom_point(data=~filter(., algorithm != "coreset")) +
  geom_line(
    data=~filter(., algorithm == "coreset"),
    mapping=aes(linetype=factor(tau)),
    stat="summary",
    fun=mean
  ) +
  geom_point(
    data=~filter(., algorithm == "coreset"),
    mapping=aes(shape=factor(tau)),
    stat="summary",
    fun=mean
  ) +
  scale_y_continuous(limits=c(0,NA)) +
  facet_wrap(vars(dataset), scale="free_y")
```

Here we take a closer look at the performance of our own algorithm: how does the radius change
as the coreset becomes larger and larger?
As expected, it becomes smaller and smaller, approaching the one found by the state 
of the art algorithms.

```{r}
#| fig-cap: Radius of the solution wrt the coreset size
#| fig-cap-location: margin
#| out-width: "100%"
#| fig-width: 10
#| fig-height: 10

load_data() |>
  ggplot(aes(tau, scaled_radius, color=algorithm)) +
  geom_line(data=~drop_na(., coreset_radius), stat="summary") +
  geom_point(data=~drop_na(., coreset_radius), size=1) +
  geom_hline(
    aes(yintercept = scaled_radius, color=algorithm),
    data=~filter(., algorithm != "coreset")
  ) +
  scale_y_continuous(limits=c(1,NA)) +
  # scale_x_continuous(limits=c(0,1), labels=scales::percent) +
  facet_grid(vars(dataset), vars(factor(k)), scales="free")
```

Notable things in @fig-time are that the KFC algorithm has some sudden jumps in the running 
time with increases in $k$, due to changes in the _joiners_ structure as $k$ increases: the 
radius becomes smaller hence the problem becomes larger.

```{r}
#| label: fig-time
#| fig-cap: Running time
#| out-width: "100%"
#| fig-width: 10
#| fig-height: 10

filterfn <- function(dat) {
  dat |>
    filter(coreset_size_frac <= 1) |>
    drop_na(coreset_size_frac)
}

load_data() |>
  ggplot(aes(y=time_s, color=algorithm, fill=algorithm)) +
  geom_line(aes(x=tau), data=filterfn, stat="summary") +
  geom_area(aes(x=tau, y=time_s), data=filterfn, alpha=0.2, stat="summary") +
  geom_area(aes(x=tau, y=coreset_time_s), data=filterfn, stat="summary") +
  # geom_point(data=filterfn, size=1) +
  geom_hline(
    aes(yintercept = time_s, color=algorithm, fill=algorithm),
    data=~filter(., algorithm != "coreset")
  ) +
  # scale_x_continuous(limits=c(0,1), labels=scales::percent) +
  facet_grid(vars(dataset), vars(factor(k)), scales="free")
```

```{r}
#| fig-width: 7
#| fig-height: 10
load_data() |>
  ggplot(aes(x=k, y=additive_violation, color=algorithm)) +
  geom_point(position="dodge") +
  scale_x_continuous(trans="log2") +
  facet_wrap(vars(dataset), scales="free", ncol=2)
```

```{ojs}
viewof dataset = Inputs.radio(new Set(data.dataset), {label: "Dataset", value: "census1990"})
viewof kval = Inputs.radio(new Set(data.k), {label: "K", value: 2})
```

```{ojs}
plotdata = transpose(data).filter(r => r.dataset == dataset && r.k == kval)
Plot.plot({
  color: {legend: true},
  x: {grid: true},
  y: {domain: [0, d3.max(plotdata, d => d.time_s)], grid: true},
  marks: [
    Plot.dot(
      plotdata,
      {
        x: "radius",
        y: "time_s",
        fill: "algorithm",
        stroke: "algorithm",
        tip: true
      }
    )
  ]
})
```

```{ojs}
viewof search = Inputs.search(
  transpose(data).filter(r => r.dataset == dataset && r.k == kval)
)
```

```{ojs}
Inputs.table(search)
```

## Plots for the paper

Here we look at the tradeoff between radius and how much time is required to achieve it

```{r fig-time-vs-radius}
#| fig-cap: Time vs radius
load_data() |>
  filter(k == 32) |>
  arrange(dataset, k, algorithm, tau) |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point() +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free", ncol=5) +
  theme_paper()
ggsave("figs/time-vs-radius-k32.png", dpi=300, width=8, height=8)
```

Now we look at the effect of changing the size of the coreset on the radius, for a fixed value of $k$.

```{r fig-tau-vs-solution-radius}
load_data() |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=scaled_radius, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=scaled_radius, color=algorithm),
    data = ~filter(., is.na(tau))
  ) +
  scale_x_continuous(trans="log2") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "coreset size",
    y = "radius (scaled by the unfair clustering radius)"
  ) +
  theme_paper()
ggsave("figs/tau-radius-k32.png", dpi=300, width=8, height=3)
```

```{r tau-vs-coreset-radius}
load_data() |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=coreset_radius, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=radius, color=algorithm),
    data = ~filter(., algorithm == "KFC")
  ) +
  scale_x_continuous(trans="log2") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "coreset size",
    y = "radius"
  ) +
  theme_paper()
ggsave("figs/tau-coreset-radius-k32.png", dpi=300, width=8, height=3)
```

The following plot is the same, with the time being the dependent variable On
`reuter_50_50` we see a slow performance because there are 50 colors, hence
there are many replicas of the same coreset point.

```{r tau-vs-time}
load_data(delta_val=0.01) |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=time_s, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=time_s, color=algorithm),
    data = ~filter(., is.na(tau))
  ) +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="log10") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="fixed", ncol=5) +
  labs(
    x = "coreset size",
    y = "time (seconds)"
  ) +
  theme_paper()
ggsave("figs/tau-time-k32.png", dpi=300, width=8, height=4)
```

```{r radius-vs-k}
load_data(delta_val=0.01) |>
  filter(is.na(tau) | (tau == 32)) |>
  ggplot(aes(x=k, y=radius, color=algorithm)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="identity") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "k",
    y = "radius"
  ) +
  theme_paper()
ggsave("figs/radius.png", dpi=300, width=8, height=4)
```

How does the tolerance $\delta$ change the radius?

```{r}
load_data(delta_val=NA) |>
  filter(k == 32) |>
  # filter(algorithm != "unfair") |>
  filter(is.na(tau) | ( tau == 32 )) |>
  ggplot(aes(x=delta, y=scaled_radius, color=algorithm)) +
  geom_point() +
  geom_line() +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  theme_paper()
```

```{r}
latex_table <- function(data, column, caption_str, label_str, k_val=32, tau_val=32) {
  data |>
    filter(k == k_val) |>
    filter(( tau == tau_val ) | is.na(tau)) |>
    mutate(dataset = fct_reorder(dataset, n)) |>
    select(dataset, algorithm, {{column}}) |>
    arrange(desc(dataset)) |>
    group_by(dataset) |>
    transmute(
      algorithm,
      c_length = max(
        str_length(dataset),
        str_length(scales::number(max({{column}}, na.rm=T), big.mark="", accuracy=0.01))
      ),
      value = str_c(
        "\\barplot[",
        c_length,
        "ex]{", {{column}}, "}{",
        max({{column}}, na.rm=T), "}"
      )
    ) |>
    ungroup() |>
    select(-c_length) |>
    pivot_wider(names_from="dataset", values_from="value") |>
    arrange(algorithm) |>
    print() |>
    kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
        escape=FALSE,
        caption=caption_str,
        label=label_str) |>
    kable_styling() |>
    #str_replace_all("table", "table*") |>
    str_replace_all("NA", "-") |>
    str_replace_all("_50_50", "")
}

selected_datasets <- c("hmda", "census1990", "athlete", "diabetes")

load_data() |>
  filter(dataset %in% selected_datasets) |>
  latex_table(radius, caption_str = "Radius for $k=32$ and $\\tau=32k$", label_str="radius-32-selected") |>
  write_file("figs/radius-k32-tau32-selected.tex")
load_data() |>
  filter(dataset %in% selected_datasets) |>
  latex_table(time_s, caption_str = "Running time for $k=32$ and $\\tau=32k$", label_str="time-32-selected") |>
  write_file("figs/time-k32-tau32-selected.tex")
```

```{r}
compact_plot <- function(data, xaes, yaes, xlab, ylab, ylog=FALSE, flabels=scales::label_number_si(), scales_val="free_y") {
  if (ylog) {
    tfun <- "log10"
  } else {
    tfun <- "identity"
  }
  data |>
    ggplot(aes({{xaes}}, {{yaes}}, color=algorithm, shape=algorithm)) +
    geom_point() +
    geom_line() +
    scale_algorithm() +
    facet_wrap(vars(dataset), scale=scales_val, ncol=4) +
    scale_y_continuous(labels=flabels, trans=tfun) +
    labs(
      x = xlab,
      y = ylab
    ) +
    theme_paper() +
    theme(legend.position="top")
}

p_radius <- load_data() |>
  filter(k >= 4) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  filter(dataset %in% selected_datasets) |>
  compact_plot(k, radius, ylab="radius", xlab="", ylog=F)
# ggsave("figs/radius-selected.pdf", width=6, height=2.5)
p_time <- load_data() |>
  filter(k >= 4) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  filter(dataset %in% selected_datasets) |>
  compact_plot(k, time_s, ylab="time (s)", xlab="k", ylog=T, 
    flabels=scales::label_number(), scales_val="fixed")
# ggsave("figs/time-selected.pdf", width=6, height=2.5)
legend <- cowplot::get_legend(p_radius)
p_radius <- p_radius + theme(
  legend.position='none'
)
p_time <- p_time + theme(legend.position='none')
p <- cowplot::plot_grid(
  legend,
  cowplot::plot_grid(
    p_radius,
    p_time,
    align="v",
    ncol=1
  ),
  ncol=1,
  rel_heights=c(1,28)
)
ggsave("figs/selected-performance.pdf", width=6, height=4)
```


```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, radius) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(dataset),
      str_length(scales::number(max(radius, na.rm=T), big.mark="", accuracy=0.01))
    ),
    radius = str_c(
      "\\barplot[",
      c_length,
      "ex]{", radius, "}{",
      max(radius, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="radius") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Radius for $k=32$ and $\\tau=32$",
      label="radius-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/radius-k32-tau32.tex")
```

```{r tab-largest-ratio}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  select(dataset, algorithm, radius) |>
  filter(algorithm %in% c("KFC", "coreset")) |>
  pivot_wider(names_from="algorithm", values_from="radius") |>
  mutate(ratio = coreset / KFC) |>
  arrange(desc(ratio)) |>
  kbl() |>
  kable_styling()
```

```{r tab-largest-ratio-2}
load_data() |>
  filter(( tau == 32 ) | is.na(tau)) |>
  select(dataset, k, algorithm, radius) |>
  filter(algorithm %in% c("KFC", "coreset")) |>
  pivot_wider(names_from="algorithm", values_from="radius") |>
  mutate(ratio = coreset / KFC) |>
  arrange(desc(ratio))
```

```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, time=time_s) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(first(dataset)),
      str_length(scales::number(max(time, na.rm=T), accuracy=0.01))
    ),
    time = str_c(
      "\\barplot[",
      c_length,
      "ex]{", time, "}{",
      max(time, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="time") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Running time in seconds, for $k=32$ and $\\tau=32$", 
      label="time-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/time-k32-tau32.tex")
```

```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, additive_violation) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(first(dataset)),
      str_length(scales::number(max(additive_violation, na.rm=T), accuracy=0.01))
    ),
    additive_violation = str_c(
      "\\barplot[",
      c_length,
      "ex]{", additive_violation, "}{",
      max(additive_violation, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="additive_violation") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Additive violation, for $k=32$ and $\\tau=32$", 
      label="time-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/violation-k32-tau32.tex")
```

### MapReduce experiments

```{r}
plot_scalability <- function(kval, ytitle=TRUE) {
  if(ytitle) {
    axis_title_element <- element_text()
    strip_text_element <- element_blank()
  } else {
    axis_title_element <- element_blank()
    strip_text_element <- element_text()
  }

  fixed_final_size <- 
    load_data(mr=TRUE) |>
    filter(k == kval) |>
    filter(parallelism %in% c(2,4,8,16)) |>
    select(dataset, k, parallelism, tau, algorithm, time_s, coreset_time_s) |>
    mutate(final_coreset_size = k * tau * parallelism) |>
    arrange(dataset, algorithm, final_coreset_size) |>
    print(n=100) |>
    filter(algorithm == "coreset-MR") |>
    filter(final_coreset_size == k*16)
  load_data(mr=TRUE) |>
    filter(k == kval) |>
    filter(tau %in% c(1, 2, 4, 8)) |>
    filter(parallelism %in% c(2,4,8,16)) |>
    ggplot(aes(parallelism, time_s, color=algorithm, linetype=factor(tau))) +
    # geom_area(
    #   aes(parallelism, time_s - coreset_time_s, fill=algorithm),
    #   inherit.aes=F,
    #   alpha=0.4,
    #   data=fixed_final_size
    # ) +
    # geom_area(
    #   aes(parallelism, time_s - coreset_time_s, fill=algorithm),
    #   inherit.aes=F,
    #   alpha=0.4,
    #   data = ~filter(., algorithm == "Bera-et-al-MR")
    # ) +
    geom_line() +
    geom_line(
      linetype="solid",
      color="white",
      data=fixed_final_size,
      linewidth=2
    ) +
    geom_line(
      linetype="solid",
      data=fixed_final_size,
      linewidth=1.2
    ) +
    geom_point() +
    geom_text(
      aes(label = tau),
      hjust=0,
      nudge_x=.1,
      show.legend=FALSE,
      data = ~filter(., parallelism == 16, algorithm == "coreset-MR", tau > 1)
    ) +
    facet_grid(vars(dataset), vars(k), scales="free_y") +
    scale_y_continuous(trans="identity") +
    scale_x_continuous(trans="log2", limits=c(2, 22)) +
    scale_algorithm() +
    guides(linetype = "none") +
    labs(
      linetype = "tau",
      color = "algorithm",
      y = "total time (s)"
    ) +
    theme_paper() +
    theme(
      axis.title.y=axis_title_element,
      strip.text.y=strip_text_element
    )
}
# p1 <- plot_scalability(kval = 32)
# p2 <- plot_scalability(kval = 100, ytitle=FALSE)
# legend = cowplot::get_legend(p1)
# p1 <- p1 + theme(
#   legend.position='none'
# )
# p2 <- p2 + theme(legend.position='none')
# p <- cowplot::plot_grid(
#   cowplot::plot_grid( p1, p2, align="h"),
#   legend, 
#   ncol=1,
#   rel_heights=c(18,1)
# )
# ggsave("figs/scalability.png", dpi=300, width=5, height=6)
```

```{r}
plot_scalable_radius <- function(kval, ytitle=TRUE) {
  if(ytitle) {
    axis_title_element <- element_text()
    strip_text_element <- element_blank()
  } else {
    axis_title_element <- element_blank()
    strip_text_element <- element_text()
  }

  fixed_final_size <- 
    load_data(mr=TRUE) |>
    filter(k == kval) |>
    filter(parallelism %in% c(2,4,8,16)) |>
    select(dataset, k, parallelism, tau, algorithm, scaled_radius) |>
    mutate(final_coreset_size = k * tau * parallelism) |>
    arrange(dataset, algorithm, final_coreset_size) |>
    print(n=100) |>
    filter(algorithm == "coreset-MR") |>
    filter(final_coreset_size == k*16)
  load_data(mr=TRUE) |>
    filter(k == kval) |>
    filter(tau %in% c(1, 2, 4, 8)) |>
    filter(parallelism %in% c(2,4,8,16)) |>
    ggplot(aes(parallelism, scaled_radius, color=algorithm, linetype=factor(tau))) +
    # geom_area(
    #   aes(parallelism, time_s - coreset_time_s, fill=algorithm),
    #   inherit.aes=F,
    #   alpha=0.4,
    #   data=fixed_final_size
    # ) +
    # geom_area(
    #   aes(parallelism, time_s - coreset_time_s, fill=algorithm),
    #   inherit.aes=F,
    #   alpha=0.4,
    #   data = ~filter(., algorithm == "Bera-et-al-MR")
    # ) +
    geom_line() +
    geom_line(
      linetype="solid",
      color="white",
      data=fixed_final_size,
      linewidth=2
    ) +
    geom_line(
      linetype="solid",
      data=fixed_final_size,
      linewidth=1.2
    ) +
    geom_point() +
    geom_text(
      aes(label = tau),
      hjust=0,
      nudge_x=.1,
      show.legend=FALSE,
      data = ~filter(., parallelism == 16, algorithm == "coreset-MR", tau > 1)
    ) +
    facet_grid(vars(dataset), vars(k), scales="free_y") +
    scale_y_continuous(trans="identity") +
    scale_x_continuous(trans="log2", limits=c(2, 22)) +
    scale_algorithm() +
    guides(linetype = "none") +
    labs(
      linetype = "tau",
      color = "algorithm",
      y = "total time (s)"
    ) +
    theme_paper() +
    theme(
      axis.title.y=axis_title_element,
      strip.text.y=strip_text_element
    )
}
# p1 <- plot_scalable_radius(kval = 32)
# p2 <- plot_scalable_radius(kval = 100, ytitle=FALSE)
# legend = cowplot::get_legend(p1)
# p1 <- p1 + theme(
#   legend.position='none'
# )
# p2 <- p2 + theme(legend.position='none')
# p <- cowplot::plot_grid(
#   cowplot::plot_grid( p1, p2, align="h"),
#   legend, 
#   ncol=1,
#   rel_heights=c(18,1)
# )
# ggsave("figs/scalability-radius.png", dpi=300, width=5, height=6)
```

```{r mr-radius}
baseline <- load_data() |>
  filter(algorithm %in% c( 'coreset', 'KFC' ), k == 32) |>
  filter(dataset %in% c('hmda', 'census1990', 'athlete')) |>
  group_by(dataset) |>
  slice_min(scaled_radius)

load_data(mr=T, do_summarise=F) |>
  filter(k==32) |>
  filter(parallelism %in% c(16)) |>
  ggplot(aes(tau, scaled_radius, color=algorithm, shape=algorithm)) +
  geom_point(stat="summary") +
  geom_line(stat="summary") +
  geom_hline(aes(yintercept = scaled_radius), data=baseline, linetype="dashed") +
  facet_wrap(vars(dataset), scales='free_y') +
  scale_algorithm() +
  theme_paper()
ggsave("figs/mapreduce-radius.png", dpi=300, width=6, height=2)
```

```{r scalable-radius}
baseline <- load_data() |>
  filter(algorithm %in% c( 'coreset', 'KFC' ), k == 32) |>
  filter(dataset %in% c('hmda', 'census1990', 'athlete')) |>
  group_by(dataset) |>
  slice_min(scaled_radius)
print(baseline)

load_data(mr=T, do_summarise=F) |>
  filter(k==32) |>
  filter(parallelism %in% c(2)) |>
  ggplot(aes(parallelism, scaled_radius, group=tau, color=algorithm)) +
  geom_point() +
  geom_line(stat="summary") +
  geom_hline(aes(yintercept = scaled_radius), data=baseline) +
  facet_wrap(vars(dataset), scales='free_y') +
  scale_algorithm() +
  theme_paper()
ggsave("figs/scalability-radius.png", dpi=300, width=6, height=3)
```

```{r scalable-time}
mr_plot <- function(data, column, column2, ylab) {
  p <- data |>
    filter(dataset %in% c("hmda", "census1990")) |>
    filter(k==32) |>
    filter(parallelism %in% c(2,4,8,16)) |>
    filter(tau %in% c(1,2)) |>
    select(dataset, algorithm, parallelism, time_s, time_assignment_s, tau, radius) |>
    print() |>
    ggplot(aes(parallelism, time_s, group=tau, color=algorithm, shape=algorithm))
    geom_area(aes(y=time_assignment_s, fill=algorithm), color=NA, alpha=0.5, position="identity") +
    geom_point() +
    geom_line() +
    facet_wrap(vars(dataset), scales='free_y', ncol=4) +
    scale_algorithm() +
    scale_y_continuous(limits=c(0,NA)) +
    scale_x_continuous(trans="log2") +
    labs(
      x = "parallelism",
      y = ylab
    ) +
    theme_paper() +
    theme(
      plot.margin = margin(0,4,0,0),
      legend.margin = margin(0,0,0,0)
    )
}
p <- load_data(mr=T) |>
  mr_plot(time_s, column2=time_assignment_s, ylab="time (s)")
ggsave("figs/scalability.pdf", dpi=300, width=6, height=2)
```

## Streaming

```{r streaming-mem-radius-paper}
streaming_compact_plot <- function(data, column, scale_val='free', include_baseline=TRUE) {
  baseline <- load_data() |>
    filter(algorithm %in% c("KFC", "coreset")) |>
    semi_join(select(data, dataset, k)) |>
    group_by(dataset) |>
    slice_min(radius)

  p <- data |>
    drop_na(streaming_memory_bytes) |>
    mutate(
      param = if_else(is.na(tau), epsilon, tau),
      bytes_per_point = streaming_memory_bytes / n
    ) |>
    group_by(algorithm, dataset, k, param) |>
    reframe(
      {{column}},
      streaming_memory_bytes = mean(streaming_memory_bytes)
    ) |>
    arrange(param) |>
    print() |>
    ggplot(aes(streaming_memory_bytes, {{column}}, color=algorithm, shape=algorithm)) +
    # geom_point() +
    geom_path(stat='summary') +
    geom_point(stat='summary') +
    # geom_hline(yintercept=1) +
    scale_algorithm() +
    labs(x = "memory (bytes)", y = "scaled radius") +
    scale_x_continuous(trans="identity", labels=scales::number_bytes, 
      guide = guide_axis(n.dodge=1),
      n.breaks=4
    ) +
    facet_wrap(vars(dataset), scale=scale_val, ncol=4) +
    theme_paper() +
    theme(
      legend.position="top",
      plot.margin = margin(0,10,0,0)
    )

  if (include_baseline) {
    p <- p + geom_hline(aes(yintercept={{column}}), linetype="dashed", data=baseline)
  }
  p
}
p <- load_data(streaming=TRUE, do_summarise=TRUE) |>
  filter(k == 32) |>
  streaming_compact_plot(radius, include_baseline=T, scale_val="free")
ggsave("figs/streaming-mem-radius.pdf", width=6, height=2.5)
```


```{r streaming-mem-time-tradeoff}
baseline <- load_data() |>
  filter(k == 32, algorithm %in% c("coreset")) |>
  filter(dataset %in% c("hmda", "census1990", "athlete")) |>
  group_by(dataset) |>
  slice_min(radius)

load_data(streaming = TRUE, do_summarise=FALSE) |>
  drop_na(streaming_memory_bytes) |>
  filter(k == 32) |>
  mutate(
    param = if_else(is.na(tau), epsilon, tau),
    throughput = n / time_s
  ) |>
  group_by(algorithm, dataset, k, param) |>
  reframe(
    time_s,
    throughput,
    streaming_memory_bytes = mean(streaming_memory_bytes)
  ) |>
  arrange(param) |>
  print() |>
  ggplot(aes(streaming_memory_bytes, time_s, color=algorithm, shape=algorithm)) +
  # geom_point() +
  geom_path(stat='summary') +
  geom_point(stat='summary') +
  geom_hline(aes(yintercept=time_s), linetype="dashed", data=baseline) +
  scale_algorithm() +
  labs(x = "memory (bytes)", y = "time (seconds)") +
  scale_x_log10(labels=scales::number_bytes, n.breaks=5) +
  facet_wrap(vars(dataset), scale='free_x')
ggsave("figs/streaming-mem-time.png", dpi=300, width=6, height=3)
```


## Plots for the presentation


```{r fig-time-vs-radius-smaller}
load_data() |>
  filter(
    k == 32,
    algorithm != "dummy",
    algorithm != "Bera-et-al",
    dataset %in% c("athlete", "diabetes")
  ) |>
  arrange(dataset, k, algorithm, tau) |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point() +
  scale_algorithm() +
  labs(x = "scaled radius", y = "time (s)") +
  facet_wrap(vars(dataset), scales="free", ncol=5) +
  theme_paper()
ggsave("presentation/figs/time-vs-radius-k32-small.png", 
  dpi=300, width=6, height=4)
```

```{r fig-time-vs-radius-larger}
load_data() |>
  filter(
    k == 32,
    algorithm != "dummy",
    algorithm != "Bera-et-al",
    dataset %in% c("hmda", "census1990")
  ) |>
  arrange(dataset, k, algorithm, tau) |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point() +
  scale_algorithm() +
labs(x = "scaled radius", y = "time (s)") +
  facet_wrap(vars(dataset), scales="free", ncol=5) +
  theme_paper()
ggsave("presentation/figs/time-vs-radius-k32-larger.png", 
  dpi=300, width=6, height=4)
```


