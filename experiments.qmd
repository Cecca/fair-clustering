---
title: "Fair clustering experiments"
execute:
  echo: false
  warning: false
  message: false
---

Crucial observation: there are some clusters where their cluster center is not contained in the cluster
itself. 
As a particular case, there are some clusters that are emtpy,
making the budget of clusters underutilized.

```{r definitions}
library(tidyverse)
library(ggpattern)
library(kableExtra)
theme_set(theme_bw() + theme(legend.position="bottom"))

theme_paper <- function() {
  # axis_line <- element_line(linewidth=0.1, color="black")
  # theme_minimal() +
  #   theme(
  #     legend.position="bottom",
  #     axis.line.x.bottom = axis_line,
  #     axis.line.y.left = axis_line
  #   )
  theme_bw() +
    theme(
      legend.position = "bottom"
    )
}

scale_algorithm <- function() {
  scale_color_manual(values = c(
    "coreset" = "#5778a4",
    "coreset-MR" = "#5778a4",
    "KFC" = "#e49444",
    "unfair" = "#d1615d",
    "Bera-et-al" = "#85b6b2",
    "Bera-et-al-MR" = "#85b6b2",
    "dummy" = "black"
  ))
}

imgdir <- "imgs"

imgpath <- function(key) {
  str_c(imgdir, key, "clustering.png", sep="/")
}

dataset_stats <- function() {
  con <- DBI::dbConnect(RSQLite::SQLite(), "results.db")
  stats <- tbl(con, "dataset_stats") |> collect()
  DBI::dbDisconnect(con)
  stats
}

load_data <- function(delta_val = 0.01, mr = FALSE) {
  con <- DBI::dbConnect(RSQLite::SQLite(), "results.db")

  if (mr) {
    algofilter <- "algorithm like '%mr%'"
    parallel_col <- "json_extract(params, '$.parallelism') as parallelism,"
  } else {
    algofilter <- "algorithm not like '%mr%'"
    parallel_col <- "1 as parallelism,"
  }

  q <- str_glue(
      "select *, json_extract(params, '$.tau') / k as tau,
       {parallel_col}
       cast(additional_metrics -> '$.coreset_radius' as real) as coreset_radius,
       cast(additional_metrics -> '$.time_coreset_s' as real) as coreset_time_s
       from results
       where dataset not like '%std'
       and {algofilter}")

  results <- tbl(con, sql(q)) |> 
    inner_join(tbl(con, "dataset_stats")) |>
    collect() |>
    mutate(
      dataset = case_when(
        dataset == "reuter_50_50" ~ "reuter",
        T ~ dataset
      ),
      algorithm = case_when(
        algorithm == "coreset-fair-k-center" ~ "coreset",
        algorithm == "kfc-k-center" ~ "KFC",
        algorithm == "unfair-k-center" ~ "unfair",
        algorithm == "bera-et-al-k-center" ~ "Bera-et-al",
        algorithm == "bera-mr-fair-k-center" ~ "Bera-et-al-MR",
        algorithm == "mr-coreset-fair-k-center" ~ "coreset-MR",
        T ~ algorithm
      ),
      algorithm = factor(algorithm, ordered=TRUE, levels=c(
        "unfair", 
        "Bera-et-al", 
        "Bera-et-al-MR", 
        "KFC", 
        "coreset",
        "coreset-MR", 
        "dummy"
      )),
      timeout_s = if_else(time_s > 30*60, 30*60, timeout_s),
      timed_out = !is.na(timeout_s),
      time_s = if_else(timed_out, timeout_s, time_s),
      scaled_time_spp = time_s / n,
      scaled_coreset_time_spp = coreset_time_s / n,
      img_path = imgpath(hdf5_key),
      coreset_size_frac = tau * k / n,
      dataset = fct_reorder(dataset, desc(n))
    ) |>
    group_by(dataset, k) |>
    mutate(scaled_radius = radius / min(radius, na.rm=T)) |>
    ungroup() |>
    group_by(dataset, algorithm, k, delta, tau, parallelism, timed_out, coreset_size_frac, n, dimensions) |>
    summarise(
      across(c(radius, scaled_radius, coreset_radius, 
                time_s, coreset_time_s,
            ), mean),
      additive_violation = max(additive_violation)
    ) |>
    ungroup()

  if (!is.na(delta_val)) {
    message(paste("filtering by delta=", delta_val))
    results <- filter(results, delta == delta_val)
  }

  DBI::dbDisconnect(con)
  results
}

results <- load_data()
```

```{r}
dataojs <- results |>
  select(dataset, k, algorithm, tau, radius, time_s, scaled_radius, additive_violation) |>
  group_by(dataset, k, algorithm, tau) |>
  summarise(
    across(c(radius, time_s, scaled_radius), mean),
    additive_violation = max(additive_violation)
  )
ojs_define(data = dataojs)
```


```{r tab-dimensions}
dataset_stats() |>
  distinct(dataset, n, dimensions) |>
  arrange(desc(n)) |>
  kbl() |>
  kable_styling()
```

The following grid of plots provides and overview of the radius/time tradeoff for all algorithms.

```{r}
#| column: screen
#| out-width: "100%"
#| fig-width: 15
#| fig-height: 15

results |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point(data=~ filter(., timed_out), shape=21, color="black", fill="white", size=4) +
  geom_point() +
  facet_grid(vars(dataset), vars(k))
```

This plot instead shows how the radius changes for changing values of `k`.
Notably, the radius flattens earlier when the fairness is considered.
One thing to remember is that, as of now, we are aiming to preserve the _exact_ ratios:
i.e. $\alpha = \beta$, there is no slack in the balancing of each cluster.

```{r}
load_data() |>
  mutate(tau = if_else(is.na(tau), 0, tau)) |>
  ggplot(aes(k, radius, color=algorithm)) +
  geom_line(data=~filter(., algorithm != "coreset")) +
  geom_point(data=~filter(., algorithm != "coreset")) +
  geom_line(
    data=~filter(., algorithm == "coreset"),
    mapping=aes(linetype=factor(tau)),
    stat="summary",
    fun=mean
  ) +
  geom_point(
    data=~filter(., algorithm == "coreset"),
    mapping=aes(shape=factor(tau)),
    stat="summary",
    fun=mean
  ) +
  scale_y_continuous(limits=c(0,NA)) +
  facet_wrap(vars(dataset), scale="free_y")
```

Here we take a closer look at the performance of our own algorithm: how does the radius change
as the coreset becomes larger and larger?
As expected, it becomes smaller and smaller, approaching the one found by the state 
of the art algorithms.

```{r}
#| fig-cap: Radius of the solution wrt the coreset size
#| fig-cap-location: margin
#| out-width: "100%"
#| fig-width: 10
#| fig-height: 10

load_data() |>
  ggplot(aes(tau, scaled_radius, color=algorithm)) +
  geom_line(data=~drop_na(., coreset_radius), stat="summary") +
  geom_point(data=~drop_na(., coreset_radius), size=1) +
  geom_hline(
    aes(yintercept = scaled_radius, color=algorithm),
    data=~filter(., algorithm != "coreset")
  ) +
  scale_y_continuous(limits=c(1,NA)) +
  # scale_x_continuous(limits=c(0,1), labels=scales::percent) +
  facet_grid(vars(dataset), vars(factor(k)), scales="free")
```

Notable things in @fig-time are that the KFC algorithm has some sudden jumps in the running 
time with increases in $k$, due to changes in the _joiners_ structure as $k$ increases: the 
radius becomes smaller hence the problem becomes larger.

```{r}
#| label: fig-time
#| fig-cap: Running time
#| out-width: "100%"
#| fig-width: 10
#| fig-height: 10

filterfn <- function(dat) {
  dat |>
    filter(coreset_size_frac <= 1) |>
    drop_na(coreset_size_frac)
}

load_data() |>
  ggplot(aes(y=time_s, color=algorithm, fill=algorithm)) +
  geom_line(aes(x=tau), data=filterfn, stat="summary") +
  geom_area(aes(x=tau, y=time_s), data=filterfn, alpha=0.2, stat="summary") +
  geom_area(aes(x=tau, y=coreset_time_s), data=filterfn, stat="summary") +
  # geom_point(data=filterfn, size=1) +
  geom_hline(
    aes(yintercept = time_s, color=algorithm, fill=algorithm),
    data=~filter(., algorithm != "coreset")
  ) +
  # scale_x_continuous(limits=c(0,1), labels=scales::percent) +
  facet_grid(vars(dataset), vars(factor(k)), scales="free")
```

```{r}
#| fig-width: 7
#| fig-height: 10
load_data() |>
  ggplot(aes(x=k, y=additive_violation, color=algorithm)) +
  geom_point(position="dodge") +
  scale_x_continuous(trans="log2") +
  facet_wrap(vars(dataset), scales="free", ncol=2)
```

```{ojs}
viewof dataset = Inputs.radio(new Set(data.dataset), {label: "Dataset", value: "census1990"})
viewof kval = Inputs.radio(new Set(data.k), {label: "K", value: 2})
```

```{ojs}
plotdata = transpose(data).filter(r => r.dataset == dataset && r.k == kval)
Plot.plot({
  color: {legend: true},
  x: {grid: true},
  y: {domain: [0, d3.max(plotdata, d => d.time_s)], grid: true},
  marks: [
    Plot.dot(
      plotdata,
      {
        x: "radius",
        y: "time_s",
        fill: "algorithm",
        stroke: "algorithm",
        tip: true
      }
    )
  ]
})
```

```{ojs}
viewof search = Inputs.search(
  transpose(data).filter(r => r.dataset == dataset && r.k == kval)
)
```

```{ojs}
Inputs.table(search)
```

## Plots for the paper

Here we look at the tradeoff between radius and how much time is required to achieve it

```{r fig-time-vs-radius}
#| fig-cap: Time vs radius
load_data() |>
  filter(k == 32) |>
  arrange(dataset, k, algorithm, tau) |>
  ggplot(aes(scaled_radius, time_s, color=algorithm, shape=algorithm)) +
  geom_point() +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free", ncol=5) +
  theme_paper()
ggsave("figs/time-vs-radius-k32.png", dpi=300, width=8, height=8)
```

Now we look at the effect of changing the size of the coreset on the radius, for a fixed value of $k$.

```{r fig-tau-vs-solution-radius}
load_data() |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=scaled_radius, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=scaled_radius, color=algorithm),
    data = ~filter(., is.na(tau))
  ) +
  scale_x_continuous(trans="log2") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "coreset size",
    y = "radius (scaled by the unfair clustering radius)"
  ) +
  theme_paper()
ggsave("figs/tau-radius-k32.png", dpi=300, width=8, height=3)
```

```{r tau-vs-coreset-radius}
load_data() |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=coreset_radius, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=radius, color=algorithm),
    data = ~filter(., algorithm == "KFC")
  ) +
  scale_x_continuous(trans="log2") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "coreset size",
    y = "radius"
  ) +
  theme_paper()
ggsave("figs/tau-coreset-radius-k32.png", dpi=300, width=8, height=3)
```

The following plot is the same, with the time being the dependent variable On
`reuter_50_50` we see a slow performance because there are 50 colors, hence
there are many replicas of the same coreset point.

```{r tau-vs-time}
load_data(delta_val=0.01) |>
  filter(k == 32) |>
  mutate(coreset_size = tau * k) |>
  ggplot(aes(x=coreset_size, y=time_s, color=algorithm)) +
  geom_point(data = ~filter(., !is.na(tau))) +
  geom_line(data = ~filter(., !is.na(tau))) +
  geom_hline(
    aes(yintercept=time_s, color=algorithm),
    data = ~filter(., is.na(tau))
  ) +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="log10") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="fixed", ncol=5) +
  labs(
    x = "coreset size",
    y = "time (seconds)"
  ) +
  theme_paper()
ggsave("figs/tau-time-k32.png", dpi=300, width=8, height=4)
```

```{r radius-vs-k}
load_data(delta_val=0.01) |>
  filter(is.na(tau) | (tau == 32)) |>
  ggplot(aes(x=k, y=radius, color=algorithm)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(trans="log2") +
  scale_y_continuous(trans="identity") +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  labs(
    x = "k",
    y = "radius"
  ) +
  theme_paper()
ggsave("figs/radius.png", dpi=300, width=8, height=4)
```

How does the tolerance $\delta$ change the radius?

```{r}
load_data(delta_val=NA) |>
  filter(k == 32) |>
  # filter(algorithm != "unfair") |>
  filter(is.na(tau) | ( tau == 32 )) |>
  ggplot(aes(x=delta, y=scaled_radius, color=algorithm)) +
  geom_point() +
  geom_line() +
  scale_algorithm() +
  facet_wrap(vars(dataset), scales="free_y", ncol=5) +
  theme_paper()
```

```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, radius) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(dataset),
      str_length(scales::number(max(radius, na.rm=T), big.mark="", accuracy=0.01))
    ),
    radius = str_c(
      "\\barplot[",
      c_length,
      "ex]{", radius, "}{",
      max(radius, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="radius") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Radius for $k=32$ and $\\tau=32$",
      label="radius-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/radius-k32-tau32.tex")
```

```{r tab-largest-ratio}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  select(dataset, algorithm, radius) |>
  filter(algorithm %in% c("KFC", "coreset")) |>
  pivot_wider(names_from="algorithm", values_from="radius") |>
  mutate(ratio = coreset / KFC) |>
  arrange(desc(ratio)) |>
  kbl() |>
  kable_styling()
```

```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, time=time_s) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(first(dataset)),
      str_length(scales::number(max(time, na.rm=T), accuracy=0.01))
    ),
    time = str_c(
      "\\barplot[",
      c_length,
      "ex]{", time, "}{",
      max(time, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="time") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Running time in seconds, for $k=32$ and $\\tau=32$", 
      label="time-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/time-k32-tau32.tex")
```

```{r}
load_data() |>
  filter(k == 32) |>
  filter(( tau == 32 ) | is.na(tau)) |>
  mutate(dataset = fct_reorder(dataset, n)) |>
  select(dataset, algorithm, additive_violation) |>
  arrange(desc(dataset)) |>
  group_by(dataset) |>
  mutate(
    c_length = max(
      str_length(first(dataset)),
      str_length(scales::number(max(additive_violation, na.rm=T), accuracy=0.01))
    ),
    additive_violation = str_c(
      "\\barplot[",
      c_length,
      "ex]{", additive_violation, "}{",
      max(additive_violation, na.rm=T), "}"
    )
  ) |>
  ungroup() |>
  select(-c_length) |>
  pivot_wider(names_from="dataset", values_from="additive_violation") |>
  arrange(algorithm) |>
  kbl(format="latex", linesep="", booktabs=T, align=c("l", rep("r", 10)),
      escape=FALSE,
      caption="Additive violation, for $k=32$ and $\\tau=32$", 
      label="time-32") |>
  kable_styling() |>
  str_replace_all("table", "table*") |>
  str_replace_all("NA", "-") |>
  str_replace_all("_50_50", "") |>
  write_file("figs/violation-k32-tau32.tex")
```

```{r}
load_data(mr=TRUE) |>
  filter(k == 32) |>
  ggplot(aes(parallelism, coreset_time_s, color=algorithm, shape=factor(tau))) +
  geom_line() +
  facet_wrap(vars(dataset)) +
  scale_algorithm() +
  theme_paper()
```




